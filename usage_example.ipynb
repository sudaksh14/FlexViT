{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9f6632",
   "metadata": {},
   "source": [
    "### Level switching\n",
    "\n",
    "Flex modules behave in much the same way as regular modules, but with the added functionality to change the level. So for a regular `Conv2d`, you might do this to create and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8694a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 98, 98])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# creates a conv2d which takes 3 channels as input and gives 20 channels output\n",
    "conv = nn.Conv2d(3, 20, kernel_size=3)\n",
    "# creates a batch of 10 images with 3 channels of 100 by 100 pixels\n",
    "x = torch.rand((10, 3, 100, 100))\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c417f38",
   "metadata": {},
   "source": [
    "To make and run a flexible `Conv2d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8d3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 98, 98])\n"
     ]
    }
   ],
   "source": [
    "import flex_modules as fm\n",
    "\n",
    "# This creates a flexible conv2d with 3 levels, where the\n",
    "# 1st, 2nd, and 3rd take 1, 2, and 3 channels of input and\n",
    "# give 10, 15, and 20 channels output.\n",
    "conv = fm.Conv2d([1, 2, 3], [10, 15, 20], kernel_size=3)\n",
    "\n",
    "# set the conv to the maximum level, which takes 3 channels\n",
    "conv.set_level_use(conv.max_level())\n",
    "x = torch.rand((10, 3, 100, 100))\n",
    "y = conv(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625b28d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given groups=1, weight of size [20, 3, 3, 3], expected input[10, 4, 100, 100] to have 3 channels, but got 4 channels instead\n",
      "0\n",
      "torch.Size([10, 10, 98, 98])\n",
      "1\n",
      "torch.Size([10, 15, 98, 98])\n",
      "2\n",
      "torch.Size([10, 20, 98, 98])\n"
     ]
    }
   ],
   "source": [
    "# We can set it to a lower level, which only takes 2 channels of input, but\n",
    "# if we try to pass the same input of 3 channels to it, it will error.\n",
    "\n",
    "conv.set_level_use(1)\n",
    "try:\n",
    "    y = conv(x)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# This is why the first layer of any flexible model should always\n",
    "# have the same input dimensions, but output dimensions can differ.\n",
    "first_conv = fm.Conv2d([3, 3, 3], [10, 15, 20], kernel_size=3)\n",
    "\n",
    "for i in range(0, first_conv.max_level() + 1):\n",
    "    first_conv.set_level_use(i)\n",
    "    y = first_conv(x)\n",
    "    print(first_conv.current_level())\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f1e85",
   "metadata": {},
   "source": [
    "This same system is also applicable to flexible models, because flexible models actually also implement the `fm.Module` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2963759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([10, 1000])\n",
      "1\n",
      "torch.Size([10, 1000])\n",
      "2\n",
      "torch.Size([10, 1000])\n"
     ]
    }
   ],
   "source": [
    "from networks import flexvit\n",
    "import utils\n",
    "\n",
    "# make flexible visual transformer with default config of 2 levels\n",
    "FLEXVIT_CONFIG = flexvit.ViTConfig()\n",
    "\n",
    "model = FLEXVIT_CONFIG.make_model().to(utils.get_device())\n",
    "x = torch.rand(10, 3, 224, 224).to(utils.get_device())\n",
    "\n",
    "for i in range(0, model.max_level() + 1):\n",
    "    model.set_level_use(i)\n",
    "    y = model(x)\n",
    "    print(model.current_level())\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c140c0",
   "metadata": {},
   "source": [
    "### Copying\n",
    "\n",
    "Being able to copy between regular layers and flexible layers can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d371e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_nets(*nets: nn.Module):\n",
    "    for net in nets:\n",
    "        for p in net.parameters():\n",
    "            p.data[:] = torch.rand(*p.shape)\n",
    "\n",
    "reg = nn.Conv2d(10, 20, kernel_size=3)\n",
    "flex = fm.Conv2d([5, 7, 10], [10, 15, 20], kernel_size=3)\n",
    "x = torch.rand(10, 10, 20, 20)\n",
    "\n",
    "flex.set_level_use(2)\n",
    "\n",
    "# copying from regular to flexible\n",
    "randomize_nets(flex, reg)\n",
    "flex.load_from_base(reg)\n",
    "assert(torch.isclose(flex(x), reg(x)).all())\n",
    "\n",
    "# copying from flexible to regular\n",
    "randomize_nets(flex, reg)\n",
    "flex.copy_to_base(reg)\n",
    "assert(torch.isclose(flex(x), reg(x)).all())\n",
    "\n",
    "# creating a new base copy\n",
    "randomize_nets(flex, reg)\n",
    "reg2 = flex.make_base_copy()\n",
    "assert(torch.isclose(flex(x), reg2(x)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458f93a",
   "metadata": {},
   "source": [
    "Copying networks and modules can also be done using `utils.flexible_model_copy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4a9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import vit\n",
    "\n",
    "reg = vit.ViTConfig().make_model().to(utils.get_device())\n",
    "flex = flexvit.ViTConfig().make_model().to(utils.get_device())\n",
    "x = torch.rand(10, 3, 224, 224).to(utils.get_device())\n",
    "\n",
    "# copying from regular to flexible\n",
    "randomize_nets(flex, reg)\n",
    "utils.flexible_model_copy(reg, flex)\n",
    "assert(torch.isclose(flex(x), reg(x)).all())\n",
    "\n",
    "# copying from flexible to regular\n",
    "randomize_nets(reg, flex)\n",
    "utils.flexible_model_copy(flex, reg)\n",
    "assert(torch.isclose(flex(x), reg(x)).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39321e97",
   "metadata": {},
   "source": [
    "### Level Deltas\n",
    "To quickly load weights from different levels in deployment, the level delta system is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5e3b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38837736\n",
      "86567656\n"
     ]
    }
   ],
   "source": [
    "model = FLEXVIT_CONFIG.make_model().to(utils.get_device())\n",
    "model.set_level_use(1)\n",
    "\n",
    "reg_model = model.make_base_copy()\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "model.set_level_use(2)\n",
    "down_delta, up_delta = model.export_level_delta()\n",
    "\n",
    "# Now we apply the updelta from level 2 to a level 1 model, which makes it level 2\n",
    "up_delta.apply(reg_model)\n",
    "print(utils.count_parameters(reg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c2605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86567656\n",
      "38837736\n"
     ]
    }
   ],
   "source": [
    "model.set_level_use(1)\n",
    "down_delta, up_delta = model.export_level_delta()\n",
    "\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "# Similarly we can apply the downdelta from level 1 to a level 2 model to bring\n",
    "# it back to level 1\n",
    "down_delta.apply(reg_model)\n",
    "print(utils.count_parameters(reg_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41494723",
   "metadata": {},
   "source": [
    "### Delta managers\n",
    "\n",
    "To make the managing of deltas simpler the delta manager is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af8cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050664\n",
      "86567656\n",
      "38837736\n",
      "22050664\n",
      "86567656\n"
     ]
    }
   ],
   "source": [
    "import networks.level_delta_utils as delta\n",
    "\n",
    "model.set_level_use(0)\n",
    "manager = delta.InMemoryDeltaManager(model)\n",
    "reg_model = manager.managed_model()\n",
    "\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "# We can now set the level of the regular model\n",
    "manager.move_to(2)\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "manager.move_to(1)\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "manager.move_to(0)\n",
    "print(utils.count_parameters(reg_model))\n",
    "\n",
    "manager.move_to(2)\n",
    "print(utils.count_parameters(reg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c6564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050664\n",
      "86567656\n",
      "38837736\n",
      "22050664\n",
      "86567656\n",
      "\n",
      "Delta file size:  354.03 MB\n",
      "Flexible model size:  350.14 MB\n",
      "Regular model size:  346.33 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Instead of having these deltas in memory all the time, there is also delta files\n",
    "\n",
    "\n",
    "DELTA_FILENAME = \"vit.delta\"\n",
    "\n",
    "# first create this delta file\n",
    "with open(DELTA_FILENAME, \"wb\") as file:\n",
    "    delta.FileDeltaManager.make_delta_file(file, model, starting_level=0)\n",
    "\n",
    "reg_config = FLEXVIT_CONFIG.create_base_config(0).no_prebuilt()\n",
    "with delta.file_delta_manager(DELTA_FILENAME, reg_config) as manager:\n",
    "    reg_model = manager.move_to(0)\n",
    "\n",
    "    print(utils.count_parameters(reg_model))\n",
    "\n",
    "    # We can now set the level of the regular model\n",
    "    reg_model = manager.move_to(2)\n",
    "    print(utils.count_parameters(reg_model))\n",
    "\n",
    "    reg_model = manager.move_to(1)\n",
    "    print(utils.count_parameters(reg_model))\n",
    "\n",
    "    reg_model = manager.move_to(0)\n",
    "    print(utils.count_parameters(reg_model))\n",
    "\n",
    "    reg_model = manager.move_to(2)\n",
    "    print(utils.count_parameters(reg_model))\n",
    "\n",
    "print()\n",
    "\n",
    "# There is some overhead in using delta files, but not a lot\n",
    "print(f\"Delta file size: {os.path.getsize(DELTA_FILENAME) / 1000000: .2f} MB\")\n",
    "print(\n",
    "    f\"Flexible model size: {utils.model_size_in_mb(model) / 1000000: .2f} MB\")\n",
    "print(\n",
    "    f\"Regular model size: {utils.model_size_in_mb(reg_model) / 1000000: .2f} MB\")\n",
    "\n",
    "if os.path.exists(DELTA_FILENAME):\n",
    "    os.remove(DELTA_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

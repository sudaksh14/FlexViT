digraph "classes" {
rankdir=BT
charset="utf-8"
"flex_modules.flexselect.AdaptSelect" [color="black", fontcolor="black", label=<{AdaptSelect|layers : Iterable[nn.Module]<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>|apply_level_delta_down(model: nn.Module, level_delta: DownDelta[tuple[torch.Tensor, ...]])<br ALIGN="LEFT"/>apply_level_delta_up(model: nn.Module, level_delta: UpDelta[tuple[torch.Tensor, ...]])<br ALIGN="LEFT"/>copy_to_base(dest: nn.Module): None<br ALIGN="LEFT"/>current_layer(): nn.Module<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[tuple[torch.Tensor, ...]], UpDelta[tuple[torch.Tensor, ...]]]<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>load_from_base(src: nn.Module): None<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.batchnorm2d.BatchNorm2d" [color="black", fontcolor="black", label=<{BatchNorm2d|<br ALIGN="LEFT"/>|base_type(): type[nn.BatchNorm2d]<br ALIGN="LEFT"/>make_base_copy(): nn.BatchNorm2d<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.class_token.ClassTokenLayer" [color="black", fontcolor="black", label=<{ClassTokenLayer|hidden_dims : Iterable[int]<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>token : Parameter<br ALIGN="LEFT"/>|apply_level_delta_down(model: vmod.ClassTokenLayer, level_delta: DownDelta[int]): None<br ALIGN="LEFT"/>apply_level_delta_up(model: vmod.ClassTokenLayer, level_delta: UpDelta[torch.Tensor]): None<br ALIGN="LEFT"/>base_type(): type[nn.Module]<br ALIGN="LEFT"/>copy_to_base(dest: vmod.ClassTokenLayer): None<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[int], UpDelta[torch.Tensor]]<br ALIGN="LEFT"/>forward(x, n)<br ALIGN="LEFT"/>load_from_base(src: vmod.ClassTokenLayer): None<br ALIGN="LEFT"/>make_base_copy(): nn.Module<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.conv2d.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|conv : Conv2d<br ALIGN="LEFT"/>in_sizes : Iterable[int]<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>max_in_size<br ALIGN="LEFT"/>max_out_size<br ALIGN="LEFT"/>out_sizes : Iterable[int]<br ALIGN="LEFT"/>|apply_level_delta_down(model: nn.Conv2d, level_delta: DownDelta[tuple[int, int]]): None<br ALIGN="LEFT"/>apply_level_delta_up(model: nn.Conv2d, level_delta: UpDelta[tuple[torch.Tensor, torch.Tensor, torch.Tensor]]): None<br ALIGN="LEFT"/>base_type(): type[nn.Conv2d]<br ALIGN="LEFT"/>copy_to_base(dest: nn.Conv2d): None<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[tuple[int, int]], UpDelta[tuple[torch.Tensor, torch.Tensor]]]<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>load_from_base(src: nn.Conv2d): None<br ALIGN="LEFT"/>make_base_copy(): nn.Conv2d<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.DownDelta" [color="black", fontcolor="black", label=<{DownDelta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"flex_modules.layer_norm.LayerNorm" [color="black", fontcolor="black", label=<{LayerNorm|<br ALIGN="LEFT"/>|apply_level_delta_down(model: nn.LayerNorm, level_delta: DownDelta[tuple[torch.Tensor, torch.Tensor]])<br ALIGN="LEFT"/>apply_level_delta_up(model: nn.LayerNorm, level_delta: UpDelta[tuple[torch.Tensor, torch.Tensor]])<br ALIGN="LEFT"/>base_type(): type[nn.LayerNorm]<br ALIGN="LEFT"/>make_base_copy(): nn.LayerNorm<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.LevelDelta" [color="black", fontcolor="black", label=<{LevelDelta|delta : T<br ALIGN="LEFT"/>|to_device()<br ALIGN="LEFT"/>verify_format()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.LevelDeltaCompatible" [color="black", fontcolor="black", label=<{LevelDeltaCompatible|<br ALIGN="LEFT"/>|<I>apply_level_delta_down</I>(module: nn.Module, level_delta: DownDelta): None<br ALIGN="LEFT"/><I>apply_level_delta_up</I>(module: nn.Module, level_delta: UpDelta): None<br ALIGN="LEFT"/><I>base_type</I>(): type[nn.Module]<br ALIGN="LEFT"/><I>export_level_delta</I>(): tuple[DownDelta, UpDelta]<br ALIGN="LEFT"/>register_self(cls: type['LevelDeltaCompatible']): type['LevelDeltaCompatible']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.LevelDeltas" [color="black", fontcolor="black", label=<{LevelDeltas|registered : dict[type[nn.Module], LevelDeltaCompatible]<br ALIGN="LEFT"/>|apply_level_delta_down(module: nn.Module, level_delta: DownDelta): None<br ALIGN="LEFT"/>apply_level_delta_up(module: nn.Module, level_delta: UpDelta): None<br ALIGN="LEFT"/>is_registered(module_type: type[nn.Module])<br ALIGN="LEFT"/>register(cls: type[LevelDeltaCompatible]): type[LevelDeltaCompatible]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|in_sizes : Iterable[int]<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>linear : Linear<br ALIGN="LEFT"/>max_in_size<br ALIGN="LEFT"/>max_out_size<br ALIGN="LEFT"/>out_sizes : Iterable[int]<br ALIGN="LEFT"/>|apply_level_delta_down(model: nn.Module, level_delta: DownDelta[tuple[int, int]]): None<br ALIGN="LEFT"/>apply_level_delta_up(model: nn.Module, level_delta: UpDelta[tuple[torch.Tensor, torch.Tensor, torch.Tensor]]): None<br ALIGN="LEFT"/>base_type(): type[nn.Linear]<br ALIGN="LEFT"/>copy_to_base(dest: nn.Linear): None<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[tuple[int, int]], UpDelta[tuple[torch.Tensor, torch.Tensor, torch.Tensor]]]<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>load_from_base(src: nn.Linear): None<br ALIGN="LEFT"/>make_base_copy(): nn.Linear<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.linear_select.LinearSelect" [color="black", fontcolor="black", label=<{LinearSelect|<br ALIGN="LEFT"/>|base_type(): type[nn.Linear]<br ALIGN="LEFT"/>make_base_copy(): nn.Linear<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.Module" [color="black", fontcolor="black", label=<{Module|<br ALIGN="LEFT"/>|<I>copy_to_base</I>(dest: nn.Module): None<br ALIGN="LEFT"/><I>current_level</I>(): int<br ALIGN="LEFT"/><I>load_from_base</I>(src: nn.Module): None<br ALIGN="LEFT"/><I>make_base_copy</I>(): nn.Module<br ALIGN="LEFT"/><I>max_level</I>(): int<br ALIGN="LEFT"/><I>set_level_use</I>(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.pos_embedding.PosEmbeddingLayer" [color="black", fontcolor="black", label=<{PosEmbeddingLayer|embedding : Parameter<br ALIGN="LEFT"/>hidden_dims : Iterable[int]<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>seq_length<br ALIGN="LEFT"/>|apply_level_delta_down(model: vmod.PosEmbeddingLayer, level_delta: DownDelta[int]): None<br ALIGN="LEFT"/>apply_level_delta_up(model: vmod.PosEmbeddingLayer, level_delta: UpDelta[torch.Tensor]): None<br ALIGN="LEFT"/>base_type(): type[nn.Module]<br ALIGN="LEFT"/>copy_to_base(dest: vmod.PosEmbeddingLayer): None<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[int], UpDelta[torch.Tensor]]<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>load_from_base(src: vmod.PosEmbeddingLayer): None<br ALIGN="LEFT"/>make_base_copy(): nn.Module<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.selfattention.SelfAttention" [color="black", fontcolor="black", label=<{SelfAttention|dropout : float<br ALIGN="LEFT"/>heads : Iterable[int]<br ALIGN="LEFT"/>in_bias : Parameter<br ALIGN="LEFT"/>in_weights : Parameter<br ALIGN="LEFT"/>level : int<br ALIGN="LEFT"/>max_heads<br ALIGN="LEFT"/>max_token_size<br ALIGN="LEFT"/>out_bias : Parameter<br ALIGN="LEFT"/>out_weights : Parameter<br ALIGN="LEFT"/>proj_token_size : Iterable[int]<br ALIGN="LEFT"/>token_size : Iterable[int]<br ALIGN="LEFT"/>|apply_level_delta_down(b: nn.MultiheadAttention, level_delta: DownDelta[tuple[int, int]]): None<br ALIGN="LEFT"/>apply_level_delta_up(b: nn.MultiheadAttention, level_delta: UpDelta[tuple[torch.Tensor, ...]]): None<br ALIGN="LEFT"/>base_type(): type[nn.MultiheadAttention]<br ALIGN="LEFT"/>copy_to_base(dest: nn.MultiheadAttention): None<br ALIGN="LEFT"/>current_level(): int<br ALIGN="LEFT"/>export_level_delta(): tuple[DownDelta[tuple[int, int]], UpDelta[tuple[torch.Tensor, ...]]]<br ALIGN="LEFT"/>forward(x: torch.Tensor)<br ALIGN="LEFT"/>load_from_base(src: nn.MultiheadAttention): None<br ALIGN="LEFT"/>make_base_copy(): nn.MultiheadAttention<br ALIGN="LEFT"/>max_level(): int<br ALIGN="LEFT"/>set_level_use(level: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"flex_modules.module.UpDelta" [color="black", fontcolor="black", label=<{UpDelta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"flex_modules.batchnorm2d.BatchNorm2d" -> "flex_modules.flexselect.AdaptSelect" [arrowhead="empty", arrowtail="none"];
"flex_modules.class_token.ClassTokenLayer" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
"flex_modules.conv2d.Conv2d" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
"flex_modules.flexselect.AdaptSelect" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
"flex_modules.layer_norm.LayerNorm" -> "flex_modules.flexselect.AdaptSelect" [arrowhead="empty", arrowtail="none"];
"flex_modules.linear.Linear" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
"flex_modules.linear_select.LinearSelect" -> "flex_modules.flexselect.AdaptSelect" [arrowhead="empty", arrowtail="none"];
"flex_modules.module.DownDelta" -> "flex_modules.module.LevelDelta" [arrowhead="empty", arrowtail="none"];
"flex_modules.module.Module" -> "flex_modules.module.LevelDeltaCompatible" [arrowhead="empty", arrowtail="none"];
"flex_modules.module.UpDelta" -> "flex_modules.module.LevelDelta" [arrowhead="empty", arrowtail="none"];
"flex_modules.pos_embedding.PosEmbeddingLayer" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
"flex_modules.selfattention.SelfAttention" -> "flex_modules.module.Module" [arrowhead="empty", arrowtail="none"];
}
